{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basline machine Learning for Emotion Detection Replication\n",
    "In this file, we aim to replicate the baseline results from the paper. We conduct classification on the same dataset for both training and testing. The results provide insights into the best achievable score for each corpus. We did everthing as in the papaer discribed.\n",
    "The Evaluation will be in the Evaluation ordner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut, cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "df_english = pd.read_csv(r'..\\Data\\English\\features_english.csv')\n",
    "df_german = pd.read_csv(r'..\\Data\\German\\features_german.csv')\n",
    "df_italian = pd.read_csv(r'..\\Data\\Italian\\features_italian.csv')\n",
    "df_urdu = pd.read_csv(r'..\\Data\\Urdu\\features_urdu.csv')\n",
    "\n",
    "languages = {\n",
    "    'english': df_english,\n",
    "    'german': df_german,\n",
    "    'italian': df_italian,\n",
    "    'urdu': df_urdu\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: [2 3 4 5]\n",
      "German: [ 3  8  9 10 11 12 13 14 15 16]\n",
      "Italian: [1 2 3 4 5 6]\n",
      "Urdu: [12 13 14 15  1  2  3  4  5  6  7  8 28 29 30 16 17 18  9 31 32 33 10 11\n",
      " 34 35 36 37 38]\n"
     ]
    }
   ],
   "source": [
    "for language, data in languages.items():\n",
    "    print(f\"{language.title()}:\", data[\"speaker_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "* We have a small dataset with unbalanced data in the German and Italian datasets. We need to be cautious about overfitting.\n",
    "* In the paper, they did not apply SMOTE, oversampling, or undersampling. Instead, they used the unbalanced data as it was.\n",
    "* In the paper, they had a test and training dataset structured as follows:\n",
    "* Test and training set:\n",
    "    Urdu: Consisted of 38 speakers. They selected 23 speakers for training and the remaining 6 for testing, using five-fold cross-validation.\n",
    "    Other languages: Used a Leave-One-Speaker-Out (LOSO) approach.\n",
    "* We followed the same approach, but since we did not have access to all 38 speakers (as not all were uploaded), we maintained the same proportion (21% for testing).\n",
    "* Since we found the procedure to be suboptimal, we conducted new baseline evaluations (available in the file baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English valence\n",
      "0    240\n",
      "1    240\n",
      "Name: count, dtype: int64\n",
      "German valence\n",
      "0    385\n",
      "1    150\n",
      "Name: count, dtype: int64\n",
      "Italian valence\n",
      "0    336\n",
      "1    252\n",
      "Name: count, dtype: int64\n",
      "Urdu valence\n",
      "0    200\n",
      "1    200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check classes\n",
    "for language, data in languages.items():\n",
    "    print(f\"{language.title()}\", data['valence'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "We integrated standardization and the classifier into a pipeline. Standardization scales the data to ensure all features are comparable by adjusting them to have a mean of zero and a standard deviation of one. It was unclear whether the original paper applied this step.  \n",
    "\n",
    "For classification, we chose Support Vector Machine, Random Forest, Logistic Regression, and XGBoost. Support Vector Machine finds the optimal hyperplane for separating classes, Random Forest is an ensemble of decision trees that improves accuracy and reduces overfitting, Logistic Regression models the probability of class membership, and XGBoost is a powerful gradient boosting algorithm known for its efficiency and performance.\n",
    "We also decided to add a dummy baseline, where the labels are randomly assigned to the data samples. We want to check how well the models perform in comparison to this dummy baseline. The paper did not include this, but we believe it is important to ensure that the results are better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "svm_model = SVC(kernel = \"linear\", C= 0.1, probability=True, random_state=42)\n",
    "logreg_model = LogisticRegression(max_iter=500,solver=\"liblinear\", random_state=42)\n",
    "xgb_model = XGBClassifier(n_estimators=50, max_depth=3, learning_rate=0.1, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "randomForest_model = RandomForestClassifier(n_estimators=50, max_depth=5,random_state=42)\n",
    "\n",
    "# Create pipelines\n",
    "pipelines = {\n",
    "    \"SVM\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"classifier\", svm_model)\n",
    "    ]),\n",
    "    \"Random Forest\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"classifier\", randomForest_model)\n",
    "    ]),\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"classifier\", logreg_model)\n",
    "    ]),\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"classifier\", xgb_model)\n",
    "    ]),\n",
    "    # random predictor\n",
    "    # Zufallsbaseline mit gewichteter Klassenverteilung\n",
    "    \"Dummy\": Pipeline([\n",
    "        (\"classifier\", DummyClassifier(strategy=\"most_frequent\"))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "In the paper, they used the unweighted average recall rate (UAR), which gives equal weight to each class, making it suitable for imbalanced datasets. UAR is equivalent to balanced accuracy.\n",
    "\n",
    "We also chose to evaluate additional metrics—\"accuracy,\" \"balanced_accuracy,\" \"f1_weighted,\" \"precision_weighted,\" and \"recall_weighted\"—for comparison. Some of these, like the F1 score, are particularly useful for imbalanced datasets.\n",
    "\n",
    "The langugae urdu has test score and score because it was special how the spilt the test and training set for urdu.\n",
    "We perform 5-fold cross-validation (GroupKFold) on the training data only.\n",
    "This gives us an estimate of how well the model performs on unseen training folds.\n",
    "After training on the full training set, we evaluate the model on the held-out test set (21% of speakers).\n",
    "This gives an additional measure of performance on completely unseen data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_feats_labs(df, dataset_name):\n",
    "    X = df.drop([\"emotion\", \"speaker_id\", \"filename\", \"valence\"], axis=1)  # Features\n",
    "    y = df[\"valence\"]  # Labels\n",
    "    groups = df[\"speaker_id\"]\n",
    "\n",
    "    if dataset_name == \"urdu\":\n",
    "        # URDU: 30 speaker for Training, 8 for Testing\n",
    "        # dont have all data, therefore 21%  (= 6 speaker) for testing\n",
    "        unique_speakers = np.random.permutation(df[\"speaker_id\"].unique())\n",
    "\n",
    "        train_speakers = unique_speakers[:22]\n",
    "        test_speakers = unique_speakers[22:]\n",
    "\n",
    "        train_idx = df[df[\"speaker_id\"].isin(train_speakers)].index\n",
    "        test_idx = df[df[\"speaker_id\"].isin(test_speakers)].index\n",
    "\n",
    "        # 5-fache Cross-Validation auf den Trainingsdaten\n",
    "        gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "        return X.loc[train_idx], y.loc[train_idx], groups.loc[train_idx], gkf, X.loc[test_idx], y.loc[test_idx]\n",
    "    else:\n",
    "        # Leave-One-Speaker-Out (LOSO)\n",
    "        logo = LeaveOneGroupOut()\n",
    "        return X, y, groups, logo, None, None\n",
    "\n",
    "def evaluate_pipelines(X, y, groups, cv, pipelines, test_X=None, test_y=None):\n",
    "    scoring_metrics = [\"accuracy\", \"balanced_accuracy\", \"f1_weighted\", \"precision_weighted\", \"recall_weighted\"]\n",
    "    results = []\n",
    "\n",
    "    for name, pipeline in pipelines.items():\n",
    "        for metric in scoring_metrics:\n",
    "            if test_X is not None and test_y is not None:\n",
    "                # URDU: 5-Fold auf Training + Testset separat\n",
    "                scores = cross_val_score(pipeline, X, y, groups=groups, cv=cv, scoring=metric)\n",
    "                pipeline.fit(X, y)\n",
    "                test_score = pipeline.score(test_X, test_y)\n",
    "                results.append([name, metric, scores.mean(), test_score])\n",
    "            else:\n",
    "                # Andere: LOSO\n",
    "                scores = cross_val_score(pipeline, X, y, groups=groups, cv=cv, scoring=metric)\n",
    "                results.append([name, metric, scores.mean()])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language, data in languages.items():\n",
    "    print(language)\n",
    "    train_X, train_y, groups, gkf, test_X, test_y = separate_feats_labs(data, language)\n",
    "\n",
    "    results = evaluate_pipelines(train_X, train_y, groups, gkf, pipelines, test_X, test_y)\n",
    "\n",
    "    # Einheitliches Format sicherstellen\n",
    "    for result in results:\n",
    "        if len(result) == 3:  # LOSO-Fall ohne Test-Set\n",
    "            result.append(None)  # Platzhalter für Test Score\n",
    "\n",
    "    # DataFrame erstellen\n",
    "    results_df = pd.DataFrame(results, columns=[\"Model\", \"Metric\", \"Score\", \"Test Score\"])\n",
    "    \n",
    "    # save the data as csv\n",
    "    results_df.to_csv(f\"../Evaluation/Baseline/{language}_replication_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.523114</td>\n",
       "      <td>0.8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>f1_weighted</td>\n",
       "      <td>0.551115</td>\n",
       "      <td>0.8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>precision_weighted</td>\n",
       "      <td>0.643557</td>\n",
       "      <td>0.8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>recall_weighted</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.660833</td>\n",
       "      <td>0.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.665204</td>\n",
       "      <td>0.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1_weighted</td>\n",
       "      <td>0.671397</td>\n",
       "      <td>0.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision_weighted</td>\n",
       "      <td>0.776636</td>\n",
       "      <td>0.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall_weighted</td>\n",
       "      <td>0.660833</td>\n",
       "      <td>0.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.524167</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.519741</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1_weighted</td>\n",
       "      <td>0.540933</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision_weighted</td>\n",
       "      <td>0.643955</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall_weighted</td>\n",
       "      <td>0.524167</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.673583</td>\n",
       "      <td>0.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>f1_weighted</td>\n",
       "      <td>0.684816</td>\n",
       "      <td>0.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>precision_weighted</td>\n",
       "      <td>0.751397</td>\n",
       "      <td>0.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>recall_weighted</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>f1_weighted</td>\n",
       "      <td>0.172326</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>precision_weighted</td>\n",
       "      <td>0.124222</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>recall_weighted</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model              Metric     Score  Test Score\n",
       "0                   SVM            accuracy  0.533333      0.8250\n",
       "1                   SVM   balanced_accuracy  0.523114      0.8250\n",
       "2                   SVM         f1_weighted  0.551115      0.8250\n",
       "3                   SVM  precision_weighted  0.643557      0.8250\n",
       "4                   SVM     recall_weighted  0.533333      0.8250\n",
       "5         Random Forest            accuracy  0.660833      0.8500\n",
       "6         Random Forest   balanced_accuracy  0.665204      0.8500\n",
       "7         Random Forest         f1_weighted  0.671397      0.8500\n",
       "8         Random Forest  precision_weighted  0.776636      0.8500\n",
       "9         Random Forest     recall_weighted  0.660833      0.8500\n",
       "10  Logistic Regression            accuracy  0.524167      0.8125\n",
       "11  Logistic Regression   balanced_accuracy  0.519741      0.8125\n",
       "12  Logistic Regression         f1_weighted  0.540933      0.8125\n",
       "13  Logistic Regression  precision_weighted  0.643955      0.8125\n",
       "14  Logistic Regression     recall_weighted  0.524167      0.8125\n",
       "15              XGBoost            accuracy  0.673333      0.8375\n",
       "16              XGBoost   balanced_accuracy  0.673583      0.8375\n",
       "17              XGBoost         f1_weighted  0.684816      0.8375\n",
       "18              XGBoost  precision_weighted  0.751397      0.8375\n",
       "19              XGBoost     recall_weighted  0.673333      0.8375\n",
       "20                Dummy            accuracy  0.300000      0.3750\n",
       "21                Dummy   balanced_accuracy  0.400000      0.3750\n",
       "22                Dummy         f1_weighted  0.172326      0.3750\n",
       "23                Dummy  precision_weighted  0.124222      0.3750\n",
       "24                Dummy     recall_weighted  0.300000      0.3750"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
