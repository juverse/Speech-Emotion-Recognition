{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross lingual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "df_train = pd.read_csv(r'..\\Data\\Urdu\\features_urdu.csv')\n",
    "df_test = pd.read_csv(r'..\\Data\\English\\features_english.csv')\n",
    "#df = pd.read_csv(r'..\\Data\\German\\features_german.csv')\n",
    "#df = pd.read_csv(r'..\\Data\\English\\features_english.csv')\n",
    "#df = pd.read_csv(r'..\\Data\\Italian\\features_italian.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Julia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:40:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "X_train = df_train.drop([\"emotion\", \"speaker_id\", \"filename\", \"valence\"], axis=1) # Features\n",
    "y_train = df_train['valence']\n",
    "\n",
    "X_test = df_test.drop([\"emotion\", \"speaker_id\", \"filename\", \"valence\"], axis=1) # Features\n",
    "y_test = df_test['valence']\n",
    "\n",
    "# Define models for comparison\n",
    "models = {\n",
    "    'SVM (linear)': SVC(kernel='linear', C=1.0, random_state=42, probability=True),\n",
    "    'SVM (rbf)': SVC(kernel='rbf', C=1.0, random_state=42, probability=True),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Save results\n",
    "results = []\n",
    "\n",
    "# Compare different models\n",
    "for name, model in models.items():\n",
    "    \n",
    "    # Define pipeline: Scaling + Model\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Fit the model on English training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    #y_prob = pipeline.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Metrics calculation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "  \n",
    "    # Save results\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Balanced Accuracy': balanced_accuracy,\n",
    "        'Precision (Weighted)': precision,\n",
    "        'Recall (Weighted)': recall,\n",
    "        'F1-Score (Weighted)': f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add random baseline/dummy\n",
    "# Generate random predictions from the existing labels\n",
    "y_random = np.random.choice(y_train.unique(), size=len(y_test), replace=True)\n",
    "\n",
    "# Metrics for Random Baseline\n",
    "random_accuracy = accuracy_score(y_test, y_random)\n",
    "random_balanced_accuracy = balanced_accuracy_score(y_test, y_random)\n",
    "random_precision = precision_score(y_test, y_random, average='weighted', zero_division=0)\n",
    "random_recall = recall_score(y_test, y_random, average='weighted')\n",
    "random_f1 = f1_score(y_test, y_random, average='weighted')\n",
    "\n",
    "# Save Random Baseline results\n",
    "results.append({\n",
    "    'Model': 'stratified Dummy',\n",
    "    'Accuracy': random_accuracy,\n",
    "    'Balanced Accuracy': random_balanced_accuracy,\n",
    "    'Precision (Weighted)': random_precision,\n",
    "    'Recall (Weighted)': random_recall,\n",
    "    'F1-Score (Weighted)': random_f1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision (Weighted)</th>\n",
       "      <th>Recall (Weighted)</th>\n",
       "      <th>F1-Score (Weighted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM (rbf)</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.543732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.518162</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.471296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM (linear)</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.522243</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.435365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.492785</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.436292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stratified Dummy</td>\n",
       "      <td>0.485417</td>\n",
       "      <td>0.485417</td>\n",
       "      <td>0.485416</td>\n",
       "      <td>0.485417</td>\n",
       "      <td>0.485414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.460417</td>\n",
       "      <td>0.460417</td>\n",
       "      <td>0.460167</td>\n",
       "      <td>0.460417</td>\n",
       "      <td>0.459570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Balanced Accuracy  Precision (Weighted)  \\\n",
       "1            SVM (rbf)  0.543750           0.543750              0.543757   \n",
       "2  Logistic Regression  0.512500           0.512500              0.518162   \n",
       "0         SVM (linear)  0.510417           0.510417              0.522243   \n",
       "4    Gradient Boosting  0.495833           0.495833              0.492785   \n",
       "5     stratified Dummy  0.485417           0.485417              0.485416   \n",
       "3        Random Forest  0.460417           0.460417              0.460167   \n",
       "\n",
       "   Recall (Weighted)  F1-Score (Weighted)  \n",
       "1           0.543750             0.543732  \n",
       "2           0.512500             0.471296  \n",
       "0           0.510417             0.435365  \n",
       "4           0.495833             0.436292  \n",
       "5           0.485417             0.485414  \n",
       "3           0.460417             0.459570  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display results\n",
    "results_df = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data as csv\n",
    "results_df.to_csv(\"../Evaluation/Crosslingual/train_urdu_test_italian.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
